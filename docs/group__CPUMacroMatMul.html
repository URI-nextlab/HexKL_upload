<!-- HTML header for doxygen 1.14.0-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.14.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>HexKL: Matrix Multiplication Functions</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">HexKL<span id="projectnumber">&#160;1.0 beta 1</span>
   </div>
   <div id="projectbrief">HexKL Public C API Documentation</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.14.0 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search/",'.html');
</script>
<script type="text/javascript">
$(function() { codefold.init(); });
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search',true);
  $(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(function(){initNavTree('group__CPUMacroMatMul.html','',''); });
</script>
<div id="container">
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="headertitle"><div class="title">Matrix Multiplication Functions <div class="ingroups"><a class="el" href="group__HexKLCPUMacro.html">HexKL CPU Macro API</a></div></div></div>
</div><!--header-->
<div class="contents">

<p>Defines functions for performing matrix multiplication using HMX.  
<a href="#details">More...</a></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 id="header-func-members" class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:ga5196434c77e06ae63469c514cac53968" id="r_ga5196434c77e06ae63469c514cac53968"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga5196434c77e06ae63469c514cac53968">sdkl_mm_tensor</a> (<a class="el" href="group__CPUMacroTypes.html#gabd7db93e58382ef55a51b930baef3c08">sdkl_tensor_platform_e</a> platform, <a class="el" href="structsdkl__tensor__t.html">sdkl_tensor_t</a> *restrict result_tensor, const <a class="el" href="structsdkl__tensor__t.html">sdkl_tensor_t</a> *restrict left_tensor, const <a class="el" href="structsdkl__tensor__t.html">sdkl_tensor_t</a> *restrict right_tensor)</td></tr>
<tr class="memdesc:ga5196434c77e06ae63469c514cac53968"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs matrix multiplication using SDKL tensor descriptors.  <br /></td></tr>
<tr class="memitem:ga271bbe1b8a7cac231fe34baab1dbb109" id="r_ga271bbe1b8a7cac231fe34baab1dbb109"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga271bbe1b8a7cac231fe34baab1dbb109">sdkl_npu_mm_f16</a> (int domain, int n_row, int n_col, int n_inner, _Float16 *A, const _Float16 *X, const _Float16 *W)</td></tr>
<tr class="memdesc:ga271bbe1b8a7cac231fe34baab1dbb109"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs matrix multiplication of FP16 activations by FP16 weights, producing FP16 results.  <br /></td></tr>
<tr class="memitem:ga425fe96792d394a4177864d52398598a" id="r_ga425fe96792d394a4177864d52398598a"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga425fe96792d394a4177864d52398598a">sdkl_npu_mm_f32f16_f32</a> (int domain, int n_row, int n_col, int n_inner, float *A, const float *X, const _Float16 *W)</td></tr>
<tr class="memdesc:ga425fe96792d394a4177864d52398598a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs matrix multiplication of FP32 activations by FP16 weights, producing FP32 results.  <br /></td></tr>
<tr class="memitem:ga0c9b29ce0b18572686268642639ad45c" id="r_ga0c9b29ce0b18572686268642639ad45c"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga0c9b29ce0b18572686268642639ad45c">sdkl_npu_mm_f16f16_f16</a> (int domain, int n_row, int n_col, int n_inner, _Float16 *A, const _Float16 *X, const _Float16 *W)</td></tr>
<tr class="memdesc:ga0c9b29ce0b18572686268642639ad45c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs matrix multiplication of FP16 activations by FP16 weights, producing FP16 results.  <br /></td></tr>
<tr class="memitem:ga95a5404ecd7761636d5282bd51c41ad1" id="r_ga95a5404ecd7761636d5282bd51c41ad1"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga95a5404ecd7761636d5282bd51c41ad1">sdkl_npu_mm_u8i8_i32</a> (int domain, int n_row, int n_col, int n_inner, int32_t *A, const uint8_t *X, const int8_t *W)</td></tr>
<tr class="memdesc:ga95a5404ecd7761636d5282bd51c41ad1"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs matrix multiplication of ui8 activations by i8 weights, producing i32 results.  <br /></td></tr>
<tr class="memitem:ga443afb28ddc982ea372b53a487f0de73" id="r_ga443afb28ddc982ea372b53a487f0de73"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga443afb28ddc982ea372b53a487f0de73">sdkl_npu_mm_u8i4_i32</a> (int domain, size_t n_row, size_t n_col, size_t n_inner, int32_t *A, const uint8_t *X, const uint8_t *W)</td></tr>
<tr class="memdesc:ga443afb28ddc982ea372b53a487f0de73"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs matrix multiplication of ui8 activations by i4 weights, producing i32 results.  <br /></td></tr>
</table>
<a name="details" id="details"></a><h2 id="header-details" class="groupheader">Detailed Description</h2>
<p>Defines functions for performing matrix multiplication using HMX. </p>
<a name="doc-func-members" id="doc-func-members"></a><h2 id="header-doc-func-members" class="groupheader">Function Documentation</h2>
<a id="ga5196434c77e06ae63469c514cac53968" name="ga5196434c77e06ae63469c514cac53968"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga5196434c77e06ae63469c514cac53968">&#9670;&#160;</a></span>sdkl_mm_tensor()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int sdkl_mm_tensor </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group__CPUMacroTypes.html#gabd7db93e58382ef55a51b930baef3c08">sdkl_tensor_platform_e</a></td>          <td class="paramname"><span class="paramname"><em>platform</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structsdkl__tensor__t.html">sdkl_tensor_t</a> *restrict</td>          <td class="paramname"><span class="paramname"><em>result_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structsdkl__tensor__t.html">sdkl_tensor_t</a> *restrict</td>          <td class="paramname"><span class="paramname"><em>left_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structsdkl__tensor__t.html">sdkl_tensor_t</a> *restrict</td>          <td class="paramname"><span class="paramname"><em>right_tensor</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Performs matrix multiplication using SDKL tensor descriptors. </p>
<p>This function multiplies two tensors representing matrices and stores the result in a third tensor. It supports quantized and transposed layouts, and leverages SDKL's hardware-accelerated kernels when the tensor metadata matches expected formats.</p>
<p>The function assumes:</p><ul>
<li><span class="tt">result_tensor</span>: output tensor, shape <span class="tt">[N_ROW, N_COL]</span>, layout and type defined by <span class="tt"><a class="el" href="structsdkl__tensor__t.html" title="Represents a tensor object in SDKL.">sdkl_tensor_t</a></span></li>
<li><span class="tt">left_tensor</span>: input tensor, shape <span class="tt">[N_ROW, N_INNER]</span>, layout and type defined by <span class="tt"><a class="el" href="structsdkl__tensor__t.html" title="Represents a tensor object in SDKL.">sdkl_tensor_t</a></span></li>
<li><span class="tt">right_tensor</span>: input tensor, shape <span class="tt">[N_COL, N_INNER]</span>, layout and type defined by <span class="tt"><a class="el" href="structsdkl__tensor__t.html" title="Represents a tensor object in SDKL.">sdkl_tensor_t</a></span></li>
</ul>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">platform</td><td>Execution platform (CPU, NPU0, NPU1, GPU) for SDKL operation. </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">result_tensor</td><td>Pointer to the output tensor descriptor. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">left_tensor</td><td>Pointer to the left-hand input tensor descriptor. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">right_tensor</td><td>Pointer to the right-hand input tensor descriptor (typically transposed weights).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><ul>
<li><span class="tt">AEE_SUCCESS</span> on successful execution.</li>
<li>Error codes from <span class="tt">AEEStdErr.h</span> (e.g., <span class="tt">AEE_EBADPARM</span>, <span class="tt">AEE_EFAILED</span>) if validation or execution fails. </li>
</ul>
</dd></dl>

</div>
</div>
<a id="ga271bbe1b8a7cac231fe34baab1dbb109" name="ga271bbe1b8a7cac231fe34baab1dbb109"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga271bbe1b8a7cac231fe34baab1dbb109">&#9670;&#160;</a></span>sdkl_npu_mm_f16()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int sdkl_npu_mm_f16 </td>
          <td>(</td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>domain</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>n_row</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>n_col</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>n_inner</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">_Float16 *</td>          <td class="paramname"><span class="paramname"><em>A</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const _Float16 *</td>          <td class="paramname"><span class="paramname"><em>X</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const _Float16 *</td>          <td class="paramname"><span class="paramname"><em>W</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Performs matrix multiplication of FP16 activations by FP16 weights, producing FP16 results. </p>
<p>Hexagon/HMX-native memory layouts. It avoids data layout and type conversion overhead, assuming the caller provides inputs in the expected formats:</p><ul>
<li><span class="tt">A</span>: output matrix, type FP16, layout AH (activation layout for the HMX unit)</li>
<li><span class="tt">X</span>: input matrix, type FP16, layout AH (activation layout for the HMX unit)</li>
<li><span class="tt">W</span>: weight matrix, type FP16, layout WH (weight layout for the HMX unit)</li>
</ul>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">domain</td><td>Which compute DSP (CDSP) core the SDKL library will interact with. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">n_row</td><td>Number of rows in matrix X and A. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">n_col</td><td>Number of columns in matrix W and A. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">n_inner</td><td>Shared dimension between X and W (columns of X, rows of W). </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">A</td><td>Pointer to the output matrix A (FP16, AH layout). </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">X</td><td>Pointer to the input matrix X (FP16, AH layout). </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">W</td><td>Pointer to the weight matrix W (FP16, WH layout).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><ul>
<li><span class="tt">AEE_SUCCESS</span> on successful execution.</li>
<li>Error codes defined in <span class="tt">AEEStdErr.h</span> (e.g., <span class="tt">AEE_EFAILED</span>, <span class="tt">AEE_EBADPARM</span>, etc.) in case of failure.</li>
</ul>
</dd></dl>
<dl class="section note"><dt>Note</dt><dd>This is the ideal kernel for FP16 matmul on Hexagon NPU, assuming the caller handles layout and type preparation. </dd></dl>

</div>
</div>
<a id="ga0c9b29ce0b18572686268642639ad45c" name="ga0c9b29ce0b18572686268642639ad45c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga0c9b29ce0b18572686268642639ad45c">&#9670;&#160;</a></span>sdkl_npu_mm_f16f16_f16()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int sdkl_npu_mm_f16f16_f16 </td>
          <td>(</td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>domain</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>n_row</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>n_col</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>n_inner</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">_Float16 *</td>          <td class="paramname"><span class="paramname"><em>A</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const _Float16 *</td>          <td class="paramname"><span class="paramname"><em>X</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const _Float16 *</td>          <td class="paramname"><span class="paramname"><em>W</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Performs matrix multiplication of FP16 activations by FP16 weights, producing FP16 results. </p>
<p>This kernel is optimized for FP16 matmul on the Hexagon NPU. It assumes that:</p><ul>
<li><span class="tt">A</span>: output matrix, type FP16, in standard row-major CPU layout.</li>
<li><span class="tt">X</span>: input matrix, type FP16, in standard row-major CPU layout.</li>
<li><span class="tt">W</span>: weight matrix, type FP16, pre-layouted in WH format (HMX unit layout).</li>
</ul>
<p>The function avoids layout and type conversion overhead for weights by requiring them to be preprocessed using <span class="tt">sdkl_cpu_f16_rm_to_f16_wh_inplace()</span>.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">domain</td><td>Which compute DSP (CDSP) core the SDKL library will interact with. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">n_row</td><td>Number of rows in matrix X and A. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">n_col</td><td>Number of columns in matrix W and A. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">n_inner</td><td>Shared dimension between X and W (columns of X, rows of W). </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">A</td><td>Pointer to the output matrix A (FP16, row-major layout). </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">X</td><td>Pointer to the input matrix X (FP16, row-major layout). </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">W</td><td>Pointer to the weight matrix W (FP16, WH layout).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><ul>
<li><span class="tt">AEE_SUCCESS</span> on successful execution.</li>
<li>Error codes defined in <span class="tt">AEEStdErr.h</span> (e.g., <span class="tt">AEE_EFAILED</span>, <span class="tt">AEE_EBADPARM</span>, etc.) in case of failure.</li>
</ul>
</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The input and output buffers must be allocated using <span class="tt"><a class="el" href="group__CPUMacroGeneral.html#gace62fcef6698d3088ef8eb6a9665071f" title="Allocates a shared CPU-NPU buffer.">sdkl_npu_alloc()</a></span> to ensure proper alignment and compatibility with the NPU. The weight matrix must be in SDKL's WH format. </dd></dl>

</div>
</div>
<a id="ga425fe96792d394a4177864d52398598a" name="ga425fe96792d394a4177864d52398598a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga425fe96792d394a4177864d52398598a">&#9670;&#160;</a></span>sdkl_npu_mm_f32f16_f32()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int sdkl_npu_mm_f32f16_f32 </td>
          <td>(</td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>domain</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>n_row</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>n_col</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>n_inner</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *</td>          <td class="paramname"><span class="paramname"><em>A</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float *</td>          <td class="paramname"><span class="paramname"><em>X</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const _Float16 *</td>          <td class="paramname"><span class="paramname"><em>W</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Performs matrix multiplication of FP32 activations by FP16 weights, producing FP32 results. </p>
<p>This kernel is optimized for mixed-precision matmul on the Hexagon NPU. It assumes that:</p><ul>
<li><span class="tt">A</span>: output matrix, type FP32, in standard row-major CPU layout.</li>
<li><span class="tt">X</span>: input matrix, type FP32, in standard row-major CPU layout.</li>
<li><span class="tt">W</span>: weight matrix, type FP16, pre-layouted in WH format (HMX unit layout).</li>
</ul>
<p>The function avoids layout and type conversion overhead for weights by requiring them to be preprocessed using <span class="tt"><a class="el" href="group__CPUMacroLayout.html#ga63ce408806d510615f60ddd55f7e6deb" title="Applies the WH (weight layout for HMX unit) data layout to weights in-place.">sdkl_cpu_rm_to_wh_f16_inplace()</a></span>.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">domain</td><td>Which compute DSP (CDSP) core the SDKL library will interact with. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">n_row</td><td>Number of rows in matrix X and A. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">n_col</td><td>Number of columns in matrix W and A. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">n_inner</td><td>Shared dimension between X and W (columns of X, rows of W). </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">A</td><td>Pointer to the output matrix A (FP32, row-major layout). </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">X</td><td>Pointer to the input matrix X (FP32, row-major layout). </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">W</td><td>Pointer to the weight matrix W (FP16, WH layout).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><ul>
<li><span class="tt">AEE_SUCCESS</span> on successful execution.</li>
<li>Error codes defined in <span class="tt">AEEStdErr.h</span> (e.g., <span class="tt">AEE_EFAILED</span>, <span class="tt">AEE_EBADPARM</span>, etc.) in case of failure.</li>
</ul>
</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The input and output buffers must be allocated using <span class="tt"><a class="el" href="group__CPUMacroGeneral.html#gace62fcef6698d3088ef8eb6a9665071f" title="Allocates a shared CPU-NPU buffer.">sdkl_npu_alloc()</a></span> to ensure proper alignment and compatibility with the NPU. The weight matrix must be in SDKL's WH format. </dd></dl>

</div>
</div>
<a id="ga443afb28ddc982ea372b53a487f0de73" name="ga443afb28ddc982ea372b53a487f0de73"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga443afb28ddc982ea372b53a487f0de73">&#9670;&#160;</a></span>sdkl_npu_mm_u8i4_i32()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int sdkl_npu_mm_u8i4_i32 </td>
          <td>(</td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>domain</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t</td>          <td class="paramname"><span class="paramname"><em>n_row</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t</td>          <td class="paramname"><span class="paramname"><em>n_col</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t</td>          <td class="paramname"><span class="paramname"><em>n_inner</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int32_t *</td>          <td class="paramname"><span class="paramname"><em>A</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint8_t *</td>          <td class="paramname"><span class="paramname"><em>X</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint8_t *</td>          <td class="paramname"><span class="paramname"><em>W</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Performs matrix multiplication of ui8 activations by i4 weights, producing i32 results. </p>
<p>This kernel is optimized for i32 matmul on the Hexagon NPU. It assumes that:</p><ul>
<li><span class="tt">A</span> : output matrix, type i32, in standard row-major CPU layout.</li>
<li><span class="tt">X</span> : input matrix, type ui8, in standard row-major CPU layout.</li>
<li><span class="tt">W</span> : weight matrix, type i4, in WH format (HMX unit layout).</li>
</ul>
<p>The function avoids layout and type conversion overhead for weights by requiring them to be preprocessed using <span class="tt"><a class="el" href="group__CPUMacroLayout.html#gab50d7525012611dbffeb5a67bd41d3e0" title="Converts a row-major i4 matrix to WH layout for HMX unit.">sdkl_cpu_rm_to_wh_i4()</a></span>.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">domain</td><td>Which compute DSP (CDSP) core the SDKL library will interact with. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">n_row</td><td>Number of rows in matrix X and A. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">n_col</td><td>Number of columns in matrix W and A. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">n_inner</td><td>Shared dimension between X and W (columns of X, rows of W). </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">A</td><td>Pointer to the output matrix A (i32, row-major layout). </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">X</td><td>Pointer to the input matrix X (ui8, row-major layout). </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">W</td><td>Pointer to the weight matrix W (i4, WH layout).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><ul>
<li><span class="tt">AEE_SUCCESS</span> on successful execution.</li>
<li>Error codes defined in <span class="tt">AEEStdErr.h</span> (e.g., <span class="tt">AEE_EFAILED</span>, <span class="tt">AEE_EBADPARM</span>, etc.) in case of failure.</li>
</ul>
</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The input and output buffers must be allocated using <span class="tt"><a class="el" href="group__CPUMacroGeneral.html#gace62fcef6698d3088ef8eb6a9665071f" title="Allocates a shared CPU-NPU buffer.">sdkl_npu_alloc()</a></span> to ensure proper alignment and compatibility with the NPU. The weight matrix must be in SDKL's WH format. </dd></dl>

</div>
</div>
<a id="ga95a5404ecd7761636d5282bd51c41ad1" name="ga95a5404ecd7761636d5282bd51c41ad1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga95a5404ecd7761636d5282bd51c41ad1">&#9670;&#160;</a></span>sdkl_npu_mm_u8i8_i32()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int sdkl_npu_mm_u8i8_i32 </td>
          <td>(</td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>domain</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>n_row</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>n_col</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>n_inner</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int32_t *</td>          <td class="paramname"><span class="paramname"><em>A</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint8_t *</td>          <td class="paramname"><span class="paramname"><em>X</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *</td>          <td class="paramname"><span class="paramname"><em>W</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Performs matrix multiplication of ui8 activations by i8 weights, producing i32 results. </p>
<p>This kernel is optimized for i32 matmul on the Hexagon NPU. It assumes that:</p><ul>
<li><span class="tt">A</span> : output matrix, type i32, in standard row-major CPU layout.</li>
<li><span class="tt">X</span> : input matrix, type ui8, in standard row-major CPU layout.</li>
<li><span class="tt">W</span> : weight matrix, type i8, pre-layouted in WH format (HMX unit layout).</li>
</ul>
<p>The function avoids layout and type conversion overhead for weights by requiring them to be preprocessed using <span class="tt"><a class="el" href="group__CPUMacroLayout.html#gaf6e54753f885e557e1ba5ea4d9e93e2f" title="Converts a row-major matrix to WH layout for HMX unit.">sdkl_cpu_rm_to_wh_i8()</a></span>.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">domain</td><td>Which compute DSP (CDSP) core the SDKL library will interact with. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">n_row</td><td>Number of rows in matrix X and A. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">n_col</td><td>Number of columns in matrix W and A. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">n_inner</td><td>Shared dimension between X and W (columns of X, rows of W). </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">A</td><td>Pointer to the output matrix A (i32, row-major layout). </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">X</td><td>Pointer to the input matrix X (ui8, row-major layout). </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">W</td><td>Pointer to the weight matrix W (i8, WH layout).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><ul>
<li><span class="tt">AEE_SUCCESS</span> on successful execution.</li>
<li>Error codes defined in <span class="tt">AEEStdErr.h</span> (e.g., <span class="tt">AEE_EFAILED</span>, <span class="tt">AEE_EBADPARM</span>, etc.) in case of failure.</li>
</ul>
</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The input and output buffers must be allocated using <span class="tt"><a class="el" href="group__CPUMacroGeneral.html#gace62fcef6698d3088ef8eb6a9665071f" title="Allocates a shared CPU-NPU buffer.">sdkl_npu_alloc()</a></span> to ensure proper alignment and compatibility with the NPU. The weight matrix must be in SDKL's WH format. </dd></dl>

</div>
</div>
</div><!-- contents -->
</div><!-- doc-content -->
<div id="page-nav" class="page-nav-panel">
<div id="page-nav-resize-handle"></div>
<div id="page-nav-tree">
<div id="page-nav-contents">
</div><!-- page-nav-contents -->
</div><!-- page-nav-tree -->
</div><!-- page-nav -->
</div><!-- container -->
<!-- HTML footer for doxygen 1.14.0-->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Copyright (c) Qualcomm Technologies, Inc. and/or its subsidiaries.</li>
  </ul>
</div>
</body>
</html>
